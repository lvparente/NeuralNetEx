{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import metrics\n",
    "from keras import activations\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Soda_split'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M.Beer', 'MD.Diet', 'MD.Orig', 'P.Cherry', 'P.diet', 'P.Orig', 'P.Rsugar', 'P.Zero']\n",
      "train directories: 8\n",
      "['M.Beer', 'MD.Diet', 'MD.Orig', 'P.Cherry', 'P.diet', 'P.Orig', 'P.Rsugar', 'P.Zero']\n",
      "test directories: 8\n"
     ]
    }
   ],
   "source": [
    "train_fnames = os.listdir(train_dir)\n",
    "print(train_fnames[:8]) \n",
    "print('train directories:', len(os.listdir(train_dir)))\n",
    "\n",
    "test_fnames = os.listdir(test_dir)\n",
    "print(test_fnames[:8]) \n",
    "print('test directories:', len(os.listdir(test_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "Rescale images by 1./255\n",
    "Split between train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5280 images belonging to 8 classes.\n",
      "Found 1335 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(200, 200),  \n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        seed=123,\n",
    "        shuffle=True,\n",
    "        subset='training')\n",
    "    \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,  \n",
    "        target_size=(200, 200),  \n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        seed=123,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 09:41:31.136198  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0701 09:41:31.168158  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0701 09:41:31.178086  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0701 09:41:31.206010  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_input = layers.Input(shape=(200, 200, 3))\n",
    "\n",
    "x = layers.Conv2D(32, (3,3), activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "output = layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = models.Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0701 09:41:31.949071  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0701 09:41:31.957051  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adagrad(lr=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0701 09:41:32.683881  1876 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0701 09:41:32.773107  1876 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 285s - loss: 0.9270 - acc: 0.6867 - val_loss: 0.4117 - val_acc: 0.8910\n",
      "Epoch 2/20\n",
      " - 311s - loss: 0.2574 - acc: 0.9325 - val_loss: 0.2461 - val_acc: 0.9144\n",
      "Epoch 3/20\n",
      " - 338s - loss: 0.1513 - acc: 0.9627 - val_loss: 0.1774 - val_acc: 0.9507\n",
      "Epoch 4/20\n",
      " - 308s - loss: 0.1081 - acc: 0.9782 - val_loss: 0.1132 - val_acc: 0.9698\n",
      "Epoch 5/20\n",
      " - 315s - loss: 0.0708 - acc: 0.9855 - val_loss: 0.1001 - val_acc: 0.9819\n",
      "Epoch 6/20\n",
      " - 290s - loss: 0.0620 - acc: 0.9865 - val_loss: 0.0664 - val_acc: 0.9869\n",
      "Epoch 7/20\n",
      " - 282s - loss: 0.0484 - acc: 0.9937 - val_loss: 0.0700 - val_acc: 0.9869\n",
      "Epoch 8/20\n",
      " - 306s - loss: 0.0397 - acc: 0.9932 - val_loss: 0.0532 - val_acc: 0.9960\n",
      "Epoch 9/20\n",
      " - 311s - loss: 0.0306 - acc: 0.9975 - val_loss: 0.0424 - val_acc: 0.9940\n",
      "Epoch 10/20\n",
      " - 294s - loss: 0.0284 - acc: 0.9955 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      " - 304s - loss: 0.0253 - acc: 0.9970 - val_loss: 0.0297 - val_acc: 0.9990\n",
      "Epoch 12/20\n",
      " - 286s - loss: 0.0218 - acc: 0.9980 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      " - 297s - loss: 0.0165 - acc: 0.9995 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      " - 273s - loss: 0.0159 - acc: 0.9997 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      " - 339s - loss: 0.0165 - acc: 0.9987 - val_loss: 0.0203 - val_acc: 0.9990\n",
      "Epoch 16/20\n",
      " - 290s - loss: 0.0137 - acc: 0.9990 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      " - 318s - loss: 0.0113 - acc: 0.9997 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      " - 298s - loss: 0.0127 - acc: 0.9990 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      " - 297s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      " - 332s - loss: 0.0103 - acc: 0.9992 - val_loss: 0.0124 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=200,  \n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50, \n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
